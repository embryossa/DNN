import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, SimpleRNN, LSTM, Conv1D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from keras.layers import Dropout
from sklearn.preprocessing import StandardScaler
from keras.regularizers import l2

selected_features = [
    "Возраст", "№ попытки", "Количество фолликулов", "Число ОКК",
    "Число инсеминированных", "2 pN", "Число дробящихся на 3 день",
    "Число Bl хор.кач-ва", "Частота оплодотворения", "Число Bl",
    "Частота дробления", "Частота формирования бластоцист",
    "Частота формирования бластоцист хорошего качества", "Частота получения ОКК",
    "Число эмбрионов 5 дня", "Заморожено эмбрионов", "Перенесено эмбрионов",
    "KPIScore"
]

# Загрузка данных из DataFrame и разделение на признаки и целевую переменную
X = df_selected[selected_features]
y = df_selected['Исход переноса']

# Разделение на обучающий, валидационный и тестовый наборы
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)


# Создание экземпляра класса StandardScaler
scaler = StandardScaler()

# Нормализация данных обучающего и тестового набора
X_train_normalized = scaler.fit_transform(X_train)
X_test_normalized = scaler.transform(X_test)

# Изменение формата данных для обучения модели
X_train_normalized = scaler.fit_transform(X_train)
X_val_normalized = scaler.transform(X_val)
X_test_normalized = scaler.transform(X_test)

X_train_reshaped = X_train_normalized.reshape((X_train_normalized.shape[0], X_train_normalized.shape[1], 1))
X_val_reshaped = X_val_normalized.reshape((X_val_normalized.shape[0], X_val_normalized.shape[1], 1))
X_test_reshaped = X_test_normalized.reshape((X_test_normalized.shape[0], X_test_normalized.shape[1], 1))

# Функция для создания модели с применением регуляризации L2 и Dropout
def create_regularized_model():
    model = Sequential()
    model.add(SimpleRNN(32, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]),
                        return_sequences=True, kernel_regularizer=regularizers.l2(0.01)))
    model.add(SimpleRNN(16, activation='relu', kernel_regularizer=regularizers.l1(0.001)))
    model.add(Dropout(0.2))  # Применение Dropout для уменьшения переобучения
    model.add(Dense(1, activation='sigmoid'))
    adam = Adam(learning_rate=0.00001)
    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Создание модели с регуляризацией
model = create_regularized_model()
# Параметры обучения
epochs = 12
batch_size = 8

# Обучение модели с использованием всех трех наборов данных
history = model.fit(X_train_reshaped, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val_reshaped, y_val))

# Получение предсказанных вероятностей от модели
y_pred = model.predict(X_test_reshaped)

# Оценка модели на тестовом наборе
test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test)

train_accuracy = history.history['accuracy']

print(f'Точность модели на тестовых данных: {test_accuracy}')

# Сохранение модели в файл
model.save('Prediction_score.h5')

